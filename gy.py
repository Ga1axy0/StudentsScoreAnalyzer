"""å¤šæ¬¡è€ƒè¯•æˆç»© & æ’åå¯è§†åŒ–çœ‹æ¿

ç‰¹æ€§ï¼š
1. æ”¯æŒå¤š Excel åŒæ—¶ä¸Šä¼  (accept_multiple_files=True)
2. å¯è‡ªå®šä¹‰æ’åºï¼ˆè€ƒè¯•æ—¶é—´ / æ‰¹æ¬¡é¡ºåºï¼‰ä¸è‡ªå®šä¹‰è€ƒè¯•æ ‡ç­¾
3. å•å­¦ç”Ÿï¼š
   - å„ç§‘åˆ†æ•°æŸ±çŠ¶å›¾ï¼ˆæ¥è‡ªæœ€æ–°ä¸€æ¬¡è€ƒè¯•ï¼‰
   - å¤šæ¬¡è€ƒè¯•æ€»åˆ†æ’åå˜åŒ–æŠ˜çº¿å›¾ï¼ˆæ ¡æ¬¡æ’åï¼‰
   - å¤šæ¬¡è€ƒè¯•é›·è¾¾å›¾å¯¹æ¯”ï¼šå±•ç¤ºå„ç§‘æ ¡æ¬¡æ’åï¼ˆå¯é€‰å¤šæ¬¡è€ƒè¯•å åŠ ï¼‰
4. å¤šå­¦ç”Ÿï¼šå¯é€‰æ‹©è‹¥å¹²å­¦ç”Ÿå¯¹æ¯”æ€»åˆ†æ’åå˜åŒ–æŠ˜çº¿å›¾

å‡è®¾ï¼š
- åŸå§‹åˆ—æ¨¡å¼ï¼šå‡†è€ƒè¯å·, ç­çº§, å§“å, æ€»åˆ†, æ€»åˆ†æ ¡æ¬¡, æ€»åˆ†ç­æ¬¡, è¯­æ–‡, è¯­æ–‡æ ¡æ¬¡, è¯­æ–‡ç­æ¬¡, æ•°å­¦, æ•°å­¦æ ¡æ¬¡, æ•°å­¦ç­æ¬¡, ...
- å®é™…æ–‡ä»¶å¯èƒ½åªæœ‰ä¸€éƒ¨åˆ†åˆ—ï¼Œè„šæœ¬æŒ‰å·²çŸ¥é¡ºåºé‡å‘½åå‰è‹¥å¹²åˆ—ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Tuple, Optional
import hashlib
import io

try:
    # å¯é€‰ï¼šæ‹–æ‹½æ’åºæ”¯æŒ
    from streamlit_sortables import sort_items  # type: ignore
    HAS_SORTABLES = True
except Exception:
    HAS_SORTABLES = False

st.set_page_config(page_title="æˆç»©å¯è§†åŒ–çœ‹æ¿", layout="wide")
st.title("ğŸ“Š æˆç»©å¯è§†åŒ–çœ‹æ¿")
st.markdown("**By Ga1axy v1.0**")

# ====== æ‰“å°ä¼˜åŒ–ï¼šæ³¨å…¥é˜²åˆ†é¡µ CSS ======
print_css = """
<style>
/* é¿å…å›¾è¡¨åœ¨æµè§ˆå™¨æ‰“å°æ—¶è¢«åˆ†é¡µæ‹†åˆ† */
@media print {
    .block-container {padding-top: 0 !important;}
    /* æ¯ä¸ª st å…ƒç´ å¤–å±‚å®¹å™¨ */
    div[data-testid="stVerticalBlock"] > div {page-break-inside: avoid;}
    /* Plotly å›¾è¡¨å®¹å™¨ */
    .js-plotly-plot, .plotly-graph-div {page-break-inside: avoid !important;}
    /* é€šç”¨å¡ç‰‡/è¡¨æ ¼ */
    .stDataFrame, .stTable {page-break-inside: avoid !important;}
    /* ç§»é™¤äº¤äº’æ§ä»¶åœ¨æ‰“å°æ—¶çš„å¤šä½™ç©ºç™½ */
    .stButton, .stCheckbox, .stTextInput, .stSelectbox, .stMultiSelect {page-break-inside: avoid !important;}
    /* è®©é¡µé¢èƒŒæ™¯ä¸ºç™½è‰² */
    body { -webkit-print-color-adjust: exact; print-color-adjust: exact; background: #ffffff; }
}
/* é™åˆ¶æœ€å¤§å®½åº¦ï¼Œä¿è¯æ‰“å°å±…ä¸­ */
@page { size: A4 portrait; margin: 10mm; }
</style>
"""
st.markdown(print_css, unsafe_allow_html=True)

# =====================================
# é…ç½® & å¸¸é‡
# =====================================
DEFAULT_SUBJECTS = ["è¯­æ–‡", "æ•°å­¦", "è‹±è¯­", "æ”¿æ²»", "å†å²", "åœ°ç†"]
# å¤åˆç§‘ç›®ï¼ˆåªæä¾›æ’åï¼Œæ— å•ç‹¬åˆ†æ•°ï¼‰
COMPOSITE_SUBJECTS = ["è¯­æ•°è‹±", "7é€‰3"]
# å¯é€‰æ‰©å±•ç§‘ç›®åˆ—è¡¨ï¼ˆåŠ å…¥å¤åˆç§‘ç›®ä½œä¸ºå¯é€‰é¡¹ï¼‰
ALL_SUBJECT_OPTIONS = DEFAULT_SUBJECTS + ["ç‰©ç†", "åŒ–å­¦", "ç”Ÿç‰©", "æŠ€æœ¯"] + COMPOSITE_SUBJECTS

# ========= é€šç”¨æ•°å€¼æ ¼å¼åŒ– =========
def _fmt_one_decimal(v):
    """è‹¥æœ‰å°æ•°ä¿ç•™ä¸€ä½ï¼›è‹¥ä¸ºæ•´æ•°åˆ™ä¸æ˜¾ç¤ºå°æ•°ï¼›ç©ºå€¼è¿”å›ç©ºä¸²ã€‚"""
    if v is None or (isinstance(v, float) and np.isnan(v)) or (isinstance(v, (np.floating,)) and np.isnan(v)):
        return ""
    try:
        f = float(v)
    except Exception:
        return str(v)
    f1 = round(f, 1)
    if float(f1).is_integer():
        return str(int(f1))
    return f"{f1:.1f}"

@st.cache_data(show_spinner=False)
def standardize_columns(df: pd.DataFrame, subjects: List[str]) -> pd.DataFrame:
    """å°†â€œå®å¤–æœŸæœ«è¡¨å¤´â€æ ¼å¼æ˜ å°„ä¸ºç»Ÿä¸€åˆ—åã€‚

    è¾“å…¥è¡¨å¤´ç¤ºä¾‹ï¼ˆç¬¬ä¸€è¡Œæ˜¯è€ƒè¯•æ ‡ç­¾ï¼Œå·²åœ¨è¯»å–æ—¶å‰”é™¤ï¼‰ï¼š
    ç­çº§ å­¦å· å§“å è¯­æ–‡ è¯­ç­ è¯­å¹´ æ•°å­¦ æ•°ç­ æ•°å¹´ è‹±è¯­ è‹±ç­ è‹±å¹´ ç‰©èµ‹ ç‰©ç­ ç‰©å¹´ åŒ–èµ‹ åŒ–ç­ åŒ–å¹´ ç”Ÿèµ‹ ç”Ÿç­ ç”Ÿå¹´ æ”¿èµ‹ æ”¿ç­ æ”¿å¹´ å²èµ‹ å²ç­ å²å¹´ åœ°èµ‹ åœ°ç­ åœ°å¹´ æŠ€èµ‹ æŠ€ç­ æŠ€å¹´ è¯­æ•°å¤– ç­æ’ å¹´æ’ 7é€‰3 ç­æ’ å¹´æ’ æ€»åˆ† ç­çº§æ’å å¹´çº§æ’å

    ç›®æ ‡ç»Ÿä¸€åˆ—ï¼š
    - åŸºç¡€ï¼šç­çº§, å‡†è€ƒè¯å·, å§“å, æ€»åˆ†, æ€»åˆ†_ç­æ¬¡(ç­çº§æ’å), æ€»åˆ†_æ ¡æ¬¡(å¹´çº§æ’å)
    - å­¦ç§‘ï¼š<ç§‘ç›®, ç§‘ç›®_ç­æ¬¡, ç§‘ç›®_æ ¡æ¬¡>
    """
    df2 = df.copy()

    # åˆ—åå»ç©ºç™½
    df2.columns = [str(c).strip() for c in df2.columns]

    # åŸºç¡€å­—æ®µæ˜ å°„
    base_map = {
        "ç­çº§": "ç­çº§",
        "å­¦å·": "å‡†è€ƒè¯å·",
        "å§“å": "å§“å",
        "æ€»åˆ†": "æ€»åˆ†",
        "ç­çº§æ’å": "æ€»åˆ†_ç­æ¬¡",
        "å¹´çº§æ’å": "æ€»åˆ†_æ ¡æ¬¡",
    }

    # å­¦ç§‘å­—æ®µæ˜ å°„ï¼ˆåˆ†æ•°/ç­æ’/å¹´æ’ï¼‰
    # æ³¨æ„ï¼šè¡¨ä¸­ç†åŒ–ç”Ÿæ”¿å²åœ°æŠ€çš„åˆ†æ•°å­—æ®µä½¿ç”¨â€œèµ‹â€å­—æ ·
    subject_source_map = {
        "è¯­æ–‡": ("è¯­æ–‡", "è¯­ç­", "è¯­å¹´"),
        "æ•°å­¦": ("æ•°å­¦", "æ•°ç­", "æ•°å¹´"),
        "è‹±è¯­": ("è‹±è¯­", "è‹±ç­", "è‹±å¹´"),
        "ç‰©ç†": ("ç‰©èµ‹", "ç‰©ç­", "ç‰©å¹´"),
        "åŒ–å­¦": ("åŒ–èµ‹", "åŒ–ç­", "åŒ–å¹´"),
        "ç”Ÿç‰©": ("ç”Ÿèµ‹", "ç”Ÿç­", "ç”Ÿå¹´"),
        "æ”¿æ²»": ("æ”¿èµ‹", "æ”¿ç­", "æ”¿å¹´"),
        "å†å²": ("å²èµ‹", "å²ç­", "å²å¹´"),
        "åœ°ç†": ("åœ°èµ‹", "åœ°ç­", "åœ°å¹´"),
        "æŠ€æœ¯": ("æŠ€èµ‹", "æŠ€ç­", "æŠ€å¹´"),
    }

    rename_map: Dict[str, str] = {}
    # åº”ç”¨åŸºç¡€æ˜ å°„ï¼ˆå­˜åœ¨æ‰æ˜ å°„ï¼‰
    for src, dst in base_map.items():
        if src in df2.columns:
            rename_map[src] = dst

    # åº”ç”¨å­¦ç§‘æ˜ å°„
    for std_subj, (score_col, cls_rank_col, grd_rank_col) in subject_source_map.items():
        if score_col in df2.columns:
            rename_map[score_col] = std_subj
        if cls_rank_col in df2.columns:
            rename_map[cls_rank_col] = f"{std_subj}_ç­æ¬¡"
        if grd_rank_col in df2.columns:
            rename_map[grd_rank_col] = f"{std_subj}_æ ¡æ¬¡"

    # å¤åˆç§‘ç›®ï¼šè¯­æ•°è‹±ï¼ˆæºï¼šè¯­æ•°å¤– ç­æ’/å¹´æ’ï¼‰ï¼Œ7é€‰3ï¼ˆæºï¼š7é€‰3 ç­æ’/å¹´æ’ï¼‰
    # å…¼å®¹â€œæ— ç©ºæ ¼â€å’Œâ€œæœ‰ç©ºæ ¼â€ä¸¤ç§å†™æ³•
    composite_candidates = [
        ("è¯­æ•°è‹±", ["è¯­æ•°è‹±", "è¯­æ•°å¤–"], ["ç­æ’", "å¹´æ’"]),
        ("7é€‰3", ["7é€‰3", "ä¸ƒé€‰ä¸‰"], ["ç­æ’", "å¹´æ’"]),
    ]

    def _col_exists(*names: str) -> Optional[str]:
        for n in names:
            if n in df2.columns:
                return n
        return None

    for std_name, bases, rank_words in composite_candidates:
        # å°è¯•åŒ¹é…ï¼š<base>ç­æ’ æˆ– "<base> ç­æ’"
        # å¹´æ’åŒç†
        for base in bases:
            cls_variants = [f"{base}ç­æ’", f"{base} ç­æ’"]
            grd_variants = [f"{base}å¹´æ’", f"{base} å¹´æ’"]
            # ä¹Ÿå…¼å®¹â€œ<base> ç­çº§æ’å/å¹´çº§æ’åâ€çš„æç«¯æƒ…å†µ
            cls_variants.extend([f"{base}ç­çº§æ’å", f"{base} ç­çº§æ’å"])
            grd_variants.extend([f"{base}å¹´çº§æ’å", f"{base} å¹´çº§æ’å"])
            cls_col = _col_exists(*cls_variants)
            grd_col = _col_exists(*grd_variants)
            if cls_col:
                rename_map[cls_col] = f"{std_name}_ç­æ¬¡"
            if grd_col:
                rename_map[grd_col] = f"{std_name}_æ ¡æ¬¡"

    df2 = df2.rename(columns=rename_map)

    # ä»…ä¿ç•™åˆ†ææ‰€éœ€åˆ—ï¼Œå»é™¤æœªæ˜ å°„çš„åŸå§‹åˆ—ï¼ˆå¦‚â€œè¯­æ•°å¤–/7é€‰3 çš„ ç­æ’/å¹´æ’â€ç­‰ï¼‰ï¼Œé¿å…é‡å¤åˆ—åå¯¼è‡´ concat å¤±è´¥
    # æ„å»ºä¿ç•™åˆ—ï¼šåŸºç¡€ + æ‰€æœ‰å­¦ç§‘ä¸å¤åˆç§‘ç›®çš„å­˜åœ¨åˆ—ï¼ˆåˆ†æ•°/ç­æ¬¡/æ ¡æ¬¡ä»»ä¸€å­˜åœ¨å³å¯ï¼‰
    all_std_subjects = list(subject_source_map.keys()) + ["è¯­æ•°è‹±", "7é€‰3"]
    keep_cols_order = [
        "ç­çº§", "å‡†è€ƒè¯å·", "å§“å", "æ€»åˆ†", "æ€»åˆ†_ç­æ¬¡", "æ€»åˆ†_æ ¡æ¬¡",
    ]
    for s in all_std_subjects:
        # åˆ†æ•°åˆ—ä¸ä¸€å®šå­˜åœ¨ï¼ˆå¦‚å¤åˆç§‘ç›®é€šå¸¸åªæœ‰æ’åï¼‰ï¼Œå› æ­¤åˆ†åˆ«åˆ¤æ–­
        if s in df2.columns:
            keep_cols_order.append(s)
        if f"{s}_ç­æ¬¡" in df2.columns:
            keep_cols_order.append(f"{s}_ç­æ¬¡")
        if f"{s}_æ ¡æ¬¡" in df2.columns:
            keep_cols_order.append(f"{s}_æ ¡æ¬¡")
    # å®é™…å­˜åœ¨çš„åˆ—
    keep_cols_order = [c for c in keep_cols_order if c in df2.columns]
    if keep_cols_order:
        df2 = df2[keep_cols_order].copy()

    # æ•°å€¼åŒ–ï¼šåˆ†æ•°ä¸æ’åå­—æ®µ
    numeric_like_cols = [c for c in df2.columns if (c == "æ€»åˆ†" or c.endswith("_ç­æ¬¡") or c.endswith("_æ ¡æ¬¡") or c in list(subject_source_map.keys()))]

    def _coerce_numeric(val):
        if isinstance(val, bytes):
            try:
                val = val.decode("utf-8", "ignore")
            except Exception:
                return pd.NA
        return val

    for c in numeric_like_cols:
        if c in df2.columns:
            try:
                df2[c] = pd.to_numeric(df2[c].map(_coerce_numeric), errors="coerce")
            except Exception:
                pass

    # ç­çº§/å§“åç­‰è½¬å­—ç¬¦ä¸²ï¼Œé¿å…åˆ†ç±»é—®é¢˜
    for c in ["ç­çº§", "å§“å", "å‡†è€ƒè¯å·"]:
        if c in df2.columns:
            try:
                df2[c] = df2[c].astype(str)
            except Exception:
                pass

    return df2

def _read_excel_bytes(file_obj) -> bytes:
    """å°†ä¸Šä¼ å¯¹è±¡è¯»å–ä¸º bytesï¼Œæ”¯æŒ Streamlit UploadedFile/æ–‡ä»¶å¥æŸ„/bytesã€‚"""
    if hasattr(file_obj, "getvalue"):
        return file_obj.getvalue()
    if hasattr(file_obj, "read"):
        return file_obj.read()
    if isinstance(file_obj, (bytes, bytearray)):
        return bytes(file_obj)
    # å…œåº•ï¼šå½“ä¼ å…¥ä¸ºè·¯å¾„å­—ç¬¦ä¸²æ—¶
    with open(file_obj, "rb") as f:
        return f.read()

def _parse_label_and_dataframe(xlsx_bytes: bytes) -> Tuple[pd.DataFrame, Optional[str]]:
    """ä» Excel bytes ä¸­æŠ½å–è€ƒè¯•æ ‡ç­¾ä¸æ•°æ®è¡¨ã€‚

    è§„åˆ™ï¼š
    - ç¬¬ä¸€è¡Œï¼ˆç´¢å¼•0ï¼‰ä¸ºè€ƒè¯•æ ‡ç­¾ï¼ˆå¯èƒ½æ˜¯åˆå¹¶å•å…ƒæ ¼ï¼Œå–è¯¥è¡Œæ‰€æœ‰éç©ºå•å…ƒæ ¼æ‹¼æ¥ï¼‰
    - æ‰¾åˆ°åŒ…å«â€œç­çº§â€å’Œâ€œå§“åâ€çš„è¡Œä½œä¸ºè¡¨å¤´è¡Œï¼Œä»ä¸‹ä¸€è¡Œå¼€å§‹ä¸ºæ•°æ®
    """
    raw = pd.read_excel(io.BytesIO(xlsx_bytes), header=None)
    exam_label: Optional[str] = None
    if not raw.empty:
        first_row_vals = [str(x).strip() for x in raw.iloc[0].tolist() if pd.notna(x) and str(x).strip() != "nan"]
        if first_row_vals:
            exam_label = " ".join(first_row_vals)

    # å¯»æ‰¾è¡¨å¤´è¡Œï¼ˆåŒ…å«å…³é”®åˆ—ï¼‰
    header_row_idx = None
    for i in range(min(len(raw), 10)):  # å‰10è¡Œå†…æœå¯»
        row_vals = [str(x).strip() for x in raw.iloc[i].tolist()]
        if ("ç­çº§" in row_vals) and ("å§“å" in row_vals):
            header_row_idx = i
            break

    if header_row_idx is None:
        # å›é€€ï¼šå‡è®¾ç¬¬1è¡Œä¸ºæ ‡ç­¾ï¼Œç¬¬2è¡Œä¸ºè¡¨å¤´
        header_row_idx = 1 if len(raw) > 1 else 0

    header_vals = [str(x).strip() for x in raw.iloc[header_row_idx].tolist()]
    data = raw.iloc[header_row_idx + 1 :].copy()
    data.columns = header_vals
    # ä¸¢å¼ƒå…¨ç©ºåˆ—
    data = data.loc[:, ~(data.isna().all())]
    # ä¸¢å¼ƒå…¨ç©ºè¡Œ
    data = data.dropna(how="all").reset_index(drop=True)
    return data, exam_label

def build_exam_dataframe(file, fallback_label: str, order: int, subjects: List[str]) -> pd.DataFrame:
    """è¯»å–å•ä¸ª Excelï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºè€ƒè¯•æ ‡ç­¾ï¼›å¦‚ç¼ºå¤±åˆ™å›é€€ä¸ºä¼ å…¥æ ‡ç­¾ã€‚"""
    xbytes = _read_excel_bytes(file)
    data_df, label_in_file = _parse_label_and_dataframe(xbytes)
    df_std = standardize_columns(data_df, subjects)
    df_std["è€ƒè¯•æ ‡ç­¾"] = label_in_file or fallback_label
    df_std["è€ƒè¯•é¡ºåº"] = order
    # ===== å¤åˆç§‘ç›®åˆ†æ•°ä¸æ’åè‡ªåŠ¨è®¡ç®— =====
    df_std = _compute_composite_scores_and_ranks(df_std)
    return df_std

def _compute_composite_scores_and_ranks(df: pd.DataFrame) -> pd.DataFrame:
    """ä¸ºå•æ¬¡è€ƒè¯•æ•°æ®å¢åŠ  è¯­æ•°è‹± ä¸ 7é€‰3 çš„åˆ†æ•°åŠç­/æ ¡æ’åï¼ˆè‹¥å°šä¸å­˜åœ¨ï¼‰ã€‚
    è¯­æ•°è‹± = è¯­æ–‡ + æ•°å­¦ + è‹±è¯­ï¼ˆå­˜åœ¨åˆ™æ±‚å’Œï¼‰
    7é€‰3 = åœ¨ [ç‰©ç†, åŒ–å­¦, ç”Ÿç‰©, æ”¿æ²», å†å², åœ°ç†, æŠ€æœ¯] ä¸­å–åˆ†æ•°æœ€é«˜çš„ 3 ç§‘æ±‚å’Œï¼ˆ>=3 ç§‘æ‰è®¡ç®—ï¼Œå¦åˆ™æ±‚å’Œå¯ç”¨ç§‘ç›®ï¼‰
    æ’åï¼šdescending åˆ†æ•°è¶Šé«˜æ’åè¶Šé å‰ï¼Œä½¿ç”¨ method='min' è·å¾—ç¨³å®šåæ¬¡ã€‚
    """
    required_cols_triple = ["è¯­æ–‡", "æ•°å­¦", "è‹±è¯­"]
    has_triple = all(c in df.columns for c in required_cols_triple)
    if "è¯­æ•°è‹±" not in df.columns and has_triple:
        df["è¯­æ•°è‹±"] = df[required_cols_triple].sum(axis=1, min_count=1)
    # 7é€‰3è®¡ç®—
    elective_cols = [c for c in ["ç‰©ç†", "åŒ–å­¦", "ç”Ÿç‰©", "æ”¿æ²»", "å†å²", "åœ°ç†", "æŠ€æœ¯"] if c in df.columns]
    if "7é€‰3" not in df.columns and elective_cols:
        def _top3_sum(row):
            vals = [row[c] for c in elective_cols if pd.notna(row[c])]
            if not vals:
                return np.nan
            vals_sorted = sorted(vals, reverse=True)
            if len(vals_sorted) >= 3:
                return sum(vals_sorted[:3])
            return sum(vals_sorted)  # ä¸è¶³3ç§‘åˆ™æ±‚å’Œå…¨éƒ¨
        df["7é€‰3"] = df.apply(_top3_sum, axis=1)
    # ç­çº§ / å¹´çº§æ’åï¼ˆæŒ‰è€ƒè¯•æ ‡ç­¾åˆ†ç»„ï¼‰
    if "è€ƒè¯•æ ‡ç­¾" in df.columns:
        # è¯­æ•°è‹±æ’å
        if "è¯­æ•°è‹±" in df.columns:
            if "è¯­æ•°è‹±_æ ¡æ¬¡" not in df.columns:
                df["è¯­æ•°è‹±_æ ¡æ¬¡"] = df.groupby("è€ƒè¯•æ ‡ç­¾")["è¯­æ•°è‹±"].rank(method="min", ascending=False)
            if "è¯­æ•°è‹±_ç­æ¬¡" not in df.columns and "ç­çº§" in df.columns:
                df["è¯­æ•°è‹±_ç­æ¬¡"] = df.groupby(["è€ƒè¯•æ ‡ç­¾", "ç­çº§"])["è¯­æ•°è‹±"].rank(method="min", ascending=False)
        # 7é€‰3æ’å
        if "7é€‰3" in df.columns:
            if "7é€‰3_æ ¡æ¬¡" not in df.columns:
                df["7é€‰3_æ ¡æ¬¡"] = df.groupby("è€ƒè¯•æ ‡ç­¾")["7é€‰3"].rank(method="min", ascending=False)
            if "7é€‰3_ç­æ¬¡" not in df.columns and "ç­çº§" in df.columns:
                df["7é€‰3_ç­æ¬¡"] = df.groupby(["è€ƒè¯•æ ‡ç­¾", "ç­çº§"])["7é€‰3"].rank(method="min", ascending=False)
    return df

def extract_exam_label_from_file(file) -> Optional[str]:
    """ä»…æŠ½å–è€ƒè¯•æ ‡ç­¾ï¼ˆç¬¬ä¸€è¡Œï¼‰ã€‚"""
    try:
        xbytes = _read_excel_bytes(file)
        raw = pd.read_excel(io.BytesIO(xbytes), header=None, nrows=1)
        if raw.empty:
            return None
        vals = [str(x).strip() for x in raw.iloc[0].tolist() if pd.notna(x) and str(x).strip() != "nan"]
        return " ".join(vals) if vals else None
    except Exception:
        return None

def extract_rank_time_series(all_df: pd.DataFrame, subjects: List[str]) -> pd.DataFrame:
    """æå–æ‰€æœ‰å­¦ç”Ÿæ‰€æœ‰è€ƒè¯•çš„æ€»åˆ†åŠç§‘ç›®æ ¡æ¬¡æ’å (é•¿è¡¨)ã€‚"""
    rank_cols = ["æ€»åˆ†_æ ¡æ¬¡"] + [f"{s}_æ ¡æ¬¡" for s in subjects if f"{s}_æ ¡æ¬¡" in all_df.columns]
    cols_needed = ["å§“å", "è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"] + rank_cols
    exist_cols = [c for c in cols_needed if c in all_df.columns]
    long_df = all_df[exist_cols].melt(id_vars=["å§“å", "è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"], var_name="é¡¹ç›®", value_name="æ ¡æ¬¡æ’å")
    return long_df

def transform_rank_for_radar(sub_df: pd.DataFrame) -> pd.DataFrame:
    """é›·è¾¾å›¾å¸Œæœ›â€œé¢ç§¯è¶Šå¤§è¶Šå¥½â€ï¼Œå°†æ’å(åæ¬¡è¶Šå°è¶Šå¥½)åè½¬å½’ä¸€ã€‚
    ç®€å•ç­–ç•¥ï¼švalue = max_rank + 1 - rank
    """
    # åªé’ˆå¯¹æ•°å€¼è¡Œ
    sub_df_num = sub_df.dropna(subset=["æ ¡æ¬¡æ’å"]).copy()
    if sub_df_num.empty:
        return sub_df
    sub_df["é›·è¾¾å€¼"] = sub_df["æ ¡æ¬¡æ’å"].apply(lambda x: (grade_total + 1 - x) if pd.notna(x) else None)
    return sub_df

# =====================================
# ä¾§è¾¹æ ï¼šä¸Šä¼ ä¸æ’åº
# =====================================
st.sidebar.header("âš™ï¸ æ•°æ®ä¸æ’åºè®¾ç½®")
uploaded_files = st.sidebar.file_uploader("ä¸Šä¼ å¤šä¸ªè€ƒè¯• Excel æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)
st.sidebar.write("---")

subjects = st.sidebar.multiselect(
    "**é€‰æ‹©å‚ä¸åˆ†æçš„ç§‘ç›®**",
    options=ALL_SUBJECT_OPTIONS,
    default=DEFAULT_SUBJECTS,
    help="æœªé€‰ä¸­çš„ç§‘ç›®å°†ä¸ä¼šå‡ºç°åœ¨åç»­å›¾è¡¨ä¸è¡¨æ ¼ä¸­ã€‚"
)
grade_total = st.sidebar.number_input(
    "å¹´çº§æ€»äººæ•°",
    min_value=1,
    max_value=5000,
    value=560,
    step=1,
    help="è¾“å…¥å½“å‰å¹´çº§çš„å­¦ç”Ÿæ€»äººæ•°ï¼Œå¯ç”¨äºåç»­æ·»åŠ æ’åç™¾åˆ†æ¯”ç­‰æŒ‡æ ‡ã€‚"
)
st.sidebar.write("---")


# åˆ†æ•°å›¾Yè½´èµ·ç‚¹è‡ªåŠ¨è°ƒæ•´è®¾ç½®
st.sidebar.write("**è°ƒæ•´Yè½´**")

auto_y_start = st.sidebar.checkbox("åˆ†æ•°å›¾è‡ªåŠ¨è°ƒæ•´Yè½´èµ·ç‚¹", value=True, help="å¼€å¯åï¼Œåˆ†æ•°ç±»æŸ±çŠ¶å›¾çš„Yè½´å°†ä»æ¥è¿‘æœ€å°åˆ†æ•°å¤„å¼€å§‹ï¼Œä»¥æ”¾å¤§å·®å¼‚ã€‚")
offset_y = st.sidebar.number_input("Yè½´èµ·ç‚¹ä¸‹ç§»å¹…åº¦", min_value=0, max_value=100, value=10, step=1, help="åœ¨æœ€å°åˆ†æ•°åŸºç¡€ä¸Šå†ä¸‹ç§»çš„å¹…åº¦ã€‚ä»…å½“å¯ç”¨è‡ªåŠ¨è°ƒæ•´æ—¶ç”Ÿæ•ˆã€‚")
st.sidebar.write("---")

if uploaded_files:
    # æ”¶é›†å¯¼å‡ºå›¾è¡¨
    export_figs: Dict[str, go.Figure] = {}
    # æ„é€ æ’åº/æ ‡ç­¾ç¼–è¾‘è¡¨
    meta_rows = []
    for idx, f in enumerate(uploaded_files, start=1):
        file_label = extract_exam_label_from_file(f) or f.name.rsplit('.', 1)[0]
        meta_rows.append({"æ–‡ä»¶å": f.name, "é»˜è®¤é¡ºåº": idx, "è‡ªå®šä¹‰é¡ºåº": idx, "è€ƒè¯•æ ‡ç­¾": file_label})
    meta_df = pd.DataFrame(meta_rows)
    # æ–°å¢â€œå¯è§†â€å¸ƒå°”åˆ—ï¼Œé»˜è®¤å…¨éƒ¨å¯è§
    if "å¯è§†" not in meta_df.columns:
        meta_df["å¯è§†"] = True
    # åŸºäºå½“å‰ä¸Šä¼ æ–‡ä»¶åç”Ÿæˆç¨³å®šæ‘˜è¦ï¼Œç”¨äºé‡ç½®æ‹–æ‹½/ç¼–è¾‘ç»„ä»¶çŠ¶æ€ï¼ˆå½“å¢åˆ æ–‡ä»¶æ—¶é‡å»ºæ§ä»¶ï¼‰
    names_for_hash = [f.name for f in uploaded_files]
    files_digest = hashlib.md5("|".join(sorted(names_for_hash)).encode("utf-8")).hexdigest()

    # åŸºç¡€è¡¨ï¼ˆå…ˆæ ¹æ®æ‹–æ‹½æ›´æ–°é¡ºåºï¼Œå†æ¸²æŸ“ç¼–è¾‘è¡¨ï¼‰
    work_meta = meta_df.copy()

    # æ‹–æ‹½æ’åºï¼ˆå¯é€‰ï¼‰
    if HAS_SORTABLES:
        with st.sidebar:
            st.markdown("**æ‹–æ‹½æ’åº**ï¼šæ‹–åŠ¨ä¸‹åˆ—é¡¹ç›®æ”¹å˜é¡ºåºï¼Œä»ä¸Šåˆ°ä¸‹ä¸ºè€ƒè¯•æ—¶é—´é¡ºåº")
            # ä»…ä½¿ç”¨è€ƒè¯•æ ‡ç­¾ä½œä¸ºæ‹–æ‹½é¡¹ï¼Œå¹¶æŒ‰å½“å‰â€œè‡ªå®šä¹‰é¡ºåºâ€æ˜¾ç¤º
            items = [f"{row['è€ƒè¯•æ ‡ç­¾']}" for _, row in work_meta.sort_values("è‡ªå®šä¹‰é¡ºåº").iterrows()]
            try:
                # å°†æ–‡ä»¶åˆ—è¡¨æ‘˜è¦çº³å…¥ keyï¼Œç¡®ä¿å½“æ–‡ä»¶å¢åˆ æ—¶ï¼Œæ‹–æ‹½ç»„ä»¶ä¼šåˆ·æ–°
                sorted_items = sort_items(items, direction="vertical", key=f"exam_drag_order_{files_digest}")
                # åŸºäºâ€œè€ƒè¯•æ ‡ç­¾â€æ„å»º æ–°é¡ºåºæ˜ å°„ï¼šæ ‡ç­¾ -> é¡ºåºç¼–å·
                def _extract_label(s: str) -> str:
                    return str(s)
                new_order_map = { _extract_label(name): idx + 1 for idx, name in enumerate(sorted_items) }
                # æ ¹æ®â€œè€ƒè¯•æ ‡ç­¾â€å†™å…¥æ–°çš„â€œè‡ªå®šä¹‰é¡ºåºâ€
                work_meta["è‡ªå®šä¹‰é¡ºåº"] = work_meta["è€ƒè¯•æ ‡ç­¾"].map(new_order_map).fillna(work_meta["è‡ªå®šä¹‰é¡ºåº"]).astype(int)
            except Exception as e:
                st.info(f"æ‹–æ‹½æ’åºç»„ä»¶ä¸å¯ç”¨ï¼Œå·²å›é€€ä¸ºè¡¨æ ¼å†…æ‰‹åŠ¨è¾“å…¥é¡ºåºã€‚({e})")
    else:
        st.sidebar.caption("å¦‚éœ€æ‹–æ‹½æ’åºï¼Œè¯·å®‰è£… streamlit-sortablesï¼Œå¹¶é‡å¯åº”ç”¨ã€‚")

    st.sidebar.write("---")
    # æ¸²æŸ“å¯ç¼–è¾‘è¡¨ï¼ˆå·²ç»æŒ‰å½“å‰é¡ºåºæ’åºåå±•ç¤ºï¼‰
    # åŒç†ï¼Œä¸ºç¼–è¾‘è¡¨è®¾ç½®åŠ¨æ€ keyï¼Œåˆ—è¡¨å˜åŒ–æ—¶é‡å»ºç¼–è¾‘æ§ä»¶
    # ä¾§è¾¹æ åªæ˜¾ç¤ºï¼šè€ƒè¯•æ ‡ç­¾ + å¯è§†ï¼ˆé¡ºåºåŸºäºæ‹–æ‹½åçš„ è‡ªå®šä¹‰é¡ºåºï¼‰
    st.sidebar.write("**å¯è§†é€‰é¡¹**ï¼šåœ¨ä¸‹è¡¨ä¸­å¯æŸ¥çœ‹è€ƒè¯•å±•ç¤ºé¡ºåºç¼–è¾‘å¯è§†çŠ¶æ€ã€‚")
    simplified_df = work_meta.sort_values("è‡ªå®šä¹‰é¡ºåº")["è€ƒè¯•æ ‡ç­¾ å¯è§†".split()]
    edited_meta = st.sidebar.data_editor(
        simplified_df,
        num_rows="dynamic",
        use_container_width=True,
        key=f"meta_editor_{files_digest}"
    )
    # å°†å¯è§†çŠ¶æ€å†™å› work_meta
    try:
        visibility_map = dict(zip(edited_meta["è€ƒè¯•æ ‡ç­¾"], edited_meta["å¯è§†"]))
        work_meta["å¯è§†"] = work_meta["è€ƒè¯•æ ‡ç­¾"].map(visibility_map).fillna(True)
    except Exception:
        pass

    # æ ¹æ®è‡ªå®šä¹‰é¡ºåºæ’åº
    # ä½¿ç”¨ work_metaï¼ˆå·²å†™å›å¯è§†çŠ¶æ€ï¼‰ç»§ç»­ï¼›è‡ªå®šä¹‰é¡ºåºæ¥è‡ªæ‹–æ‹½ç»“æœ
    try:
        edited_meta_sorted = work_meta.sort_values("è‡ªå®šä¹‰é¡ºåº")
    except Exception:
        edited_meta_sorted = work_meta

    visible_meta = edited_meta_sorted[edited_meta_sorted["å¯è§†"].fillna(True)] if "å¯è§†" in edited_meta_sorted.columns else edited_meta_sorted

    label_map: Dict[str, Dict] = {row["æ–‡ä»¶å"]: {"æ ‡ç­¾": row["è€ƒè¯•æ ‡ç­¾"], "é¡ºåº": row["è‡ªå®šä¹‰é¡ºåº"]} for _, row in visible_meta.iterrows()}
    # ä¾›å›¾è¡¨ä½¿ç”¨çš„è€ƒè¯•æ ‡ç­¾é¡ºåºï¼ˆä»…æ¥è‡ªå¯è§†çš„è€ƒè¯•ï¼‰
    exam_label_order = list(visible_meta["è€ƒè¯•æ ‡ç­¾"].astype(str).values)

    # ç»„åˆæ‰€æœ‰è€ƒè¯•æ•°æ®
    exam_dfs = []
    visible_files = set(visible_meta["æ–‡ä»¶å"].astype(str).tolist())
    for f in uploaded_files:
        if f.name in visible_files:
            info = label_map[f.name]
            exam_dfs.append(build_exam_dataframe(f, info["æ ‡ç­¾"], info["é¡ºåº"], subjects))
    if not exam_dfs:
        st.warning("æ‰€æœ‰è€ƒè¯•å‡è¢«è®¾ä¸ºä¸å¯è§†ï¼Œæš‚æ— æ•°æ®ã€‚è¯·åœ¨ä¾§è¾¹æ å‹¾é€‰â€˜å¯è§†â€™åç»§ç»­ã€‚")
        st.stop()
    all_exams_df = pd.concat(exam_dfs, ignore_index=True)
    all_exams_df.sort_values(["è€ƒè¯•é¡ºåº"], inplace=True)

    # ================= ç­çº§ç­›é€‰ =================
    st.sidebar.write("---")
    if "ç­çº§" in all_exams_df.columns:
        classes = sorted([c for c in all_exams_df["ç­çº§"].dropna().astype(str).unique()])
    else:
        classes = []
    if classes:
        selected_classes = st.sidebar.multiselect("**ç­›é€‰ç­çº§**", classes, default=classes)
        filtered_df = all_exams_df[all_exams_df["ç­çº§"].astype(str).isin(selected_classes)] if selected_classes else all_exams_df.iloc[0:0]
    else:
        filtered_df = all_exams_df

    # ================= å•å­¦ç”Ÿé€‰æ‹© =================
    all_students = sorted(filtered_df["å§“å"].dropna().unique())
    if not all_students:
        st.warning("æœªæ£€æµ‹åˆ°ä»»ä½•å­¦ç”Ÿå§“åï¼Œè¯·æ£€æŸ¥åˆ—åæˆ–æ–‡ä»¶å†…å®¹ã€‚")
        st.stop()

    col_a, col_b = st.columns([1,1])
    with col_a:
        student_name = st.selectbox("**é€‰æ‹©å•ä¸ªå­¦ç”Ÿ**", all_students)
    # æŠ˜çº¿å›¾å¯¹æ¯”é€‰é¡¹å·²ç§»åŠ¨åˆ°â€œæ’åæ—¶é—´åºåˆ—â€çš„ç§‘ç›®é€‰æ‹©ä¸‹æ–¹

   
    # ================= è¯¥å­¦ç”Ÿå…¨éƒ¨è€ƒè¯•æˆç»©æ˜ç»† =================
    st.subheader("ğŸ“„ è¯¥å­¦ç”Ÿå…¨éƒ¨è€ƒè¯•æ˜ç»†")
    score_cols_exist = (["æ€»åˆ†"] if "æ€»åˆ†" in filtered_df.columns else []) + [c for c in subjects if c in filtered_df.columns]
    # å•ç§‘ä¸æ€»åˆ†åŒºåˆ†å¼€ï¼šæ˜ç»†è¡¨ä»å¯åŒæ—¶å±•ç¤º
    score_cols_subjects_only = [c for c in subjects if c in filtered_df.columns]
    score_cols_exist = (["æ€»åˆ†"] if "æ€»åˆ†" in filtered_df.columns else []) + score_cols_subjects_only
    if score_cols_exist:
        score_long = filtered_df[filtered_df["å§“å"] == student_name][["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å"] + score_cols_exist].copy()
        score_long["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(score_long["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)
        score_pivot = score_long.sort_values("è€ƒè¯•é¡ºåº").set_index("è€ƒè¯•æ ‡ç­¾")[score_cols_exist]
        # é™æ€æ ¼å¼åŒ–ï¼šä¸€ä½å°æ•°ï¼ˆä»…éœ€è¦æ—¶ï¼‰
        score_pivot_fmt = score_pivot.applymap(lambda v: ("" if pd.isna(v) else (str(int(round(float(v),1))) if round(float(v),1).is_integer() else f"{round(float(v),1):.1f}")) if pd.api.types.is_number(v) else v)
        st.table(score_pivot_fmt)
    else:
        st.info("æ— ç§‘ç›®æˆç»©åˆ—å¯ä¾›å±•ç¤ºã€‚")
    st.markdown("---")

    # ================= å•å­¦ç”Ÿæ‰€æœ‰æ’åæ˜ç»†è¡¨ =================
    ts_long = extract_rank_time_series(filtered_df, subjects)
    # ä½¿ç”¨è€ƒè¯•æ ‡ç­¾ä½œä¸ºåˆ—ï¼Œæ›´ç›´è§‚
    student_all_raw = ts_long[ts_long["å§“å"] == student_name].copy()
    # ä¿æŒæ ‡ç­¾é¡ºåº
    student_all_raw["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(student_all_raw["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)
    student_all = student_all_raw.pivot_table(index=["é¡¹ç›®"], columns="è€ƒè¯•æ ‡ç­¾", values="æ ¡æ¬¡æ’å")
    # é‡æ–°æ’åºè¡Œï¼šæ€»åˆ†ä¼˜å…ˆï¼Œå…¶æ¬¡å„ç§‘
    desired_rows = ["æ€»åˆ†_æ ¡æ¬¡"] + [f"{s}_æ ¡æ¬¡" for s in subjects if f"{s}_æ ¡æ¬¡" in student_all.index]
    student_all = student_all.reindex(desired_rows)
    student_all_fmt = student_all.applymap(lambda v: ("" if pd.isna(v) else (str(int(round(float(v),1))) if round(float(v),1).is_integer() else f"{round(float(v),1):.1f}")) if pd.api.types.is_number(v) else v)
    st.table(student_all_fmt)

    # ================= æ’åæ—¶é—´åºåˆ— =================
    # å¯é€‰æ‹©æŸ¥çœ‹çš„é¡¹ç›®ï¼šæ€»åˆ† æˆ– å„ç§‘ï¼ˆåŸºäºå­˜åœ¨çš„â€œ*_æ ¡æ¬¡â€é¡¹ç›®ï¼‰
    proj_keys = [p for p in ts_long["é¡¹ç›®"].dropna().unique().tolist() if isinstance(p, str) and p.endswith("_æ ¡æ¬¡")]
    # å°†å†…éƒ¨é”®æ˜ å°„ä¸ºå±•ç¤ºåï¼ˆæ€»åˆ†_æ ¡æ¬¡ -> æ€»åˆ†ï¼›è¯­æ–‡_æ ¡æ¬¡ -> è¯­æ–‡ï¼‰
    def _proj_disp(k: str) -> str:
        return "æ€»åˆ†" if k == "æ€»åˆ†_æ ¡æ¬¡" else k.replace("_æ ¡æ¬¡", "")
    options_disp = [_proj_disp(k) for k in proj_keys]
    # ä¸ºäº†ç¨³å®šé¡ºåºï¼ŒæŒ‰ç…§ subjects ä¸â€œæ€»åˆ†â€ä¼˜å…ˆçš„é¡ºåºé‡æ’
    ordered_keys = []
    if "æ€»åˆ†_æ ¡æ¬¡" in proj_keys:
        ordered_keys.append("æ€»åˆ†_æ ¡æ¬¡")
    for s in subjects:
        k = f"{s}_æ ¡æ¬¡"
        if k in proj_keys and k not in ordered_keys:
            ordered_keys.append(k)
    # è¡¥å……ä»»ä½•æœªè¦†ç›–çš„é”®
    for k in proj_keys:
        if k not in ordered_keys:
            ordered_keys.append(k)
    ordered_disp = [_proj_disp(k) for k in ordered_keys]
    default_disp = "æ€»åˆ†" if "æ€»åˆ†_æ ¡æ¬¡" in ordered_keys else (ordered_disp[0] if ordered_disp else "")
    selected_disp = st.multiselect(
        "é€‰æ‹©æŸ¥çœ‹é¡¹ç›®ï¼ˆæ€»åˆ†æˆ–ç§‘ç›®ï¼‰(å¯å¤šé€‰)",
        ordered_disp,
        default=([default_disp] if default_disp else []),
        help="å¯é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªé¡¹ç›®è¿›è¡ŒæŠ˜çº¿å¯¹æ¯”"
    ) if ordered_disp else []
    # å°†â€œæŠ˜çº¿å›¾å¯¹æ¯”å¤šä¸ªå­¦ç”Ÿâ€çš„é€‰é¡¹ç§»åŠ¨è‡³æ­¤ï¼ˆç´§è·Ÿç§‘ç›®/æ€»åˆ†é€‰æ‹©ï¼‰
    # ---- åŒæ­¥å¤šå­¦ç”Ÿå¯¹æ¯”é€‰æ‹©é€»è¾‘ï¼ˆé¿å… default ä¸ session_state åŒæ—¶è®¾ç½®å†²çªï¼‰ ----
    # åŸå› ï¼šå½“ä½¿ç”¨å›ºå®š key æ—¶ï¼Œè‹¥åœ¨ Session State ä¸­å·²ç»è®¾ç½®äº†è¯¥ key çš„å€¼ï¼ŒåŒæ—¶åˆåœ¨ç»„ä»¶ä¸Šæä¾›äº† defaultï¼Œä¼šè§¦å‘å†²çªæç¤ºã€‚
    # æ–¹æ¡ˆï¼š
    #  - é¦–æ¬¡æ¸²æŸ“ï¼šä»…é€šè¿‡ default æä¾›åˆå€¼ï¼ˆä¸é¢„å…ˆå†™ session_state[list_key]ï¼‰ã€‚
    #  - ä¹‹åæ¸²æŸ“ï¼šå¦‚éœ€è°ƒæ•´ï¼Œå…ˆæ›´æ–° session_state[list_key]ï¼Œå†åˆ›å»ºç»„ä»¶ä¸”ä¸ä¼  defaultã€‚
    anchor_key = "_anchor_student_for_multiline"
    list_key = "multi_students_for_line"

    if list_key in st.session_state:
        # å·²åˆå§‹åŒ–è¿‡ï¼šæ ¹æ®å½“å‰ä¸»å­¦ç”Ÿä¸å¯é€‰é¡¹åŠ¨æ€ç»´æŠ¤åˆ—è¡¨
        if st.session_state.get(anchor_key) != student_name:
            st.session_state[list_key] = [student_name]
            st.session_state[anchor_key] = student_name
        else:
            # æ¸…ç†æ‰å·²ç»ä¸åœ¨å€™é€‰ä¸­çš„å­¦ç”Ÿ
            st.session_state[list_key] = [s for s in st.session_state[list_key] if s in all_students]
            # ç¡®ä¿ä¸»å­¦ç”Ÿåœ¨åˆ—è¡¨ä¸­
            if student_name not in st.session_state[list_key]:
                st.session_state[list_key].insert(0, student_name)

        multi_students = st.multiselect(
            "æŠ˜çº¿å›¾å¯¹æ¯”å¤šä¸ªå­¦ç”Ÿ (å¯é€‰)",
            all_students,
            key=list_key,
            help="å½“ä¸Šé¢é€‰æ‹©çš„ä¸»å­¦ç”Ÿæ”¹å˜æ—¶ï¼Œæ­¤åˆ—è¡¨ä¼šè‡ªåŠ¨åŒæ­¥åŒ…å«è¯¥å­¦ç”Ÿã€‚"
        )
    else:
        # é¦–æ¬¡æ¸²æŸ“ï¼šé€šè¿‡ default è®¾ç½®åˆå€¼ï¼ŒåŒæ—¶è®°å½•é”šå®šå­¦ç”Ÿã€‚
        st.session_state[anchor_key] = student_name
        multi_students = st.multiselect(
            "æŠ˜çº¿å›¾å¯¹æ¯”å¤šä¸ªå­¦ç”Ÿ (å¯é€‰)",
            all_students,
            default=[student_name],
            key=list_key,
            help="å½“ä¸Šé¢é€‰æ‹©çš„ä¸»å­¦ç”Ÿæ”¹å˜æ—¶ï¼Œæ­¤åˆ—è¡¨ä¼šè‡ªåŠ¨åŒæ­¥åŒ…å«è¯¥å­¦ç”Ÿã€‚"
        )
    # æ–°å¢ï¼šé€‰æ‹©æŸ¥çœ‹å†…å®¹ï¼ˆåˆ†æ•° / æ ¡æ¬¡æ’å / ç­æ¬¡æ’åï¼‰
    view_options = ["æ ¡æ¬¡æ’å", "ç­æ¬¡æ’å", "åˆ†æ•°"]
    view_choice = st.selectbox("é€‰æ‹©æŸ¥çœ‹å†…å®¹", view_options, index=0, key="series_view_type")

    fig_line = go.Figure()
    if selected_disp:
        # æ ¹æ®æŸ¥çœ‹å†…å®¹é€‰æ‹©æ•°æ®åˆ—ä¸æ¥æºï¼ˆæ”¯æŒå¤šé¡¹ç›®ï¼‰
        y_label = ""
        reverse_y = False
        if view_choice == "æ ¡æ¬¡æ’å":
            selected_keys = [("æ€»åˆ†_æ ¡æ¬¡" if disp == "æ€»åˆ†" else f"{disp}_æ ¡æ¬¡") for disp in selected_disp]
            df_tmp = ts_long[ts_long["é¡¹ç›®"].isin(selected_keys)].copy()
            df_tmp = df_tmp[df_tmp["å§“å"].isin(multi_students)]
            df_tmp["å€¼"] = df_tmp["æ ¡æ¬¡æ’å"]
            df_tmp["é¡¹ç›®æ˜¾ç¤ºå"] = df_tmp["é¡¹ç›®"].apply(lambda k: "æ€»åˆ†" if k == "æ€»åˆ†_æ ¡æ¬¡" else str(k).replace("_æ ¡æ¬¡", ""))
            line_df = df_tmp[["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å", "é¡¹ç›®æ˜¾ç¤ºå", "å€¼"]]
            y_label = "æ ¡æ¬¡æ’å"
            reverse_y = True
        elif view_choice == "ç­æ¬¡æ’å":
            selected_cols = [("æ€»åˆ†_ç­æ¬¡" if disp == "æ€»åˆ†" else f"{disp}_ç­æ¬¡") for disp in selected_disp]
            exist_cols = [c for c in selected_cols if c in filtered_df.columns]
            if exist_cols:
                df_tmp = filtered_df[["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å"] + exist_cols].copy()
                df_tmp = df_tmp[df_tmp["å§“å"].isin(multi_students)]
                melted = df_tmp.melt(id_vars=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å"], value_vars=exist_cols, var_name="é¡¹ç›®", value_name="å€¼")
                melted["é¡¹ç›®æ˜¾ç¤ºå"] = melted["é¡¹ç›®"].apply(lambda k: "æ€»åˆ†" if k == "æ€»åˆ†_ç­æ¬¡" else str(k).replace("_ç­æ¬¡", ""))
                line_df = melted[["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å", "é¡¹ç›®æ˜¾ç¤ºå", "å€¼"]]
            else:
                line_df = pd.DataFrame(columns=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å", "é¡¹ç›®æ˜¾ç¤ºå", "å€¼"])  # ç©º
            y_label = "ç­æ¬¡æ’å"
            reverse_y = True
        else:  # åˆ†æ•°
            selected_cols = [("æ€»åˆ†" if disp == "æ€»åˆ†" else disp) for disp in selected_disp]
            exist_cols = [c for c in selected_cols if c in filtered_df.columns]
            if exist_cols:
                df_tmp = filtered_df[["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å"] + exist_cols].copy()
                df_tmp = df_tmp[df_tmp["å§“å"].isin(multi_students)]
                melted = df_tmp.melt(id_vars=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å"], value_vars=exist_cols, var_name="é¡¹ç›®æ˜¾ç¤ºå", value_name="å€¼")
                line_df = melted[["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å", "é¡¹ç›®æ˜¾ç¤ºå", "å€¼"]]
            else:
                line_df = pd.DataFrame(columns=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "å§“å", "é¡¹ç›®æ˜¾ç¤ºå", "å€¼"])  # ç©º
            y_label = "åˆ†æ•°"
            reverse_y = False

        # ä½¿ç”¨è€ƒè¯•æ ‡ç­¾ä½œä¸º X è½´ï¼Œä½†ä¿æŒé¡ºåº
        if not line_df.empty:
            line_df["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(line_df["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)

        # ç”Ÿæˆå›¾æˆ–æç¤º
        if line_df.empty:
            st.warning("æ‰€é€‰å­¦ç”Ÿ/ç§‘ç›®æ²¡æœ‰å¯ç”¨çš„æ•°æ®ã€‚")
        else:
            line_df = line_df.copy()
            line_df["æ˜¾ç¤ºå€¼"] = line_df["å€¼"].apply(_fmt_one_decimal)
            # åŒæ—¶æŒ‰å­¦ç”Ÿä¸é¡¹ç›®åŒºåˆ†æ›²çº¿
            fig_line = px.line(
                line_df.sort_values("è€ƒè¯•é¡ºåº"),
                x="è€ƒè¯•æ ‡ç­¾",
                y="å€¼",
                # é¢œè‰²åŒºåˆ†ç§‘ç›®/é¡¹ç›®ï¼ˆå«â€œæ€»åˆ†â€ï¼‰
                color="é¡¹ç›®æ˜¾ç¤ºå",
                # çº¿å‹åŒºåˆ†å­¦ç”Ÿ
                line_dash="å§“å",
                # åŒæ­¥ä½¿ç”¨ç¬¦å·åŒºåˆ†å­¦ç”Ÿï¼Œæå‡è¾¨è¯†åº¦
                symbol="å§“å",
                text="æ˜¾ç¤ºå€¼",
                markers=True,
                category_orders={"è€ƒè¯•æ ‡ç­¾": exam_label_order},
                title=f"{','.join(selected_disp)} {y_label}å˜åŒ–"
            )
            fig_line.update_traces(mode="lines+markers+text", texttemplate="%{text}", textposition="top center")
            if reverse_y:
                fig_line.update_yaxes(autorange="reversed")
            export_figs[f"{','.join(selected_disp)} {y_label}å˜åŒ–æŠ˜çº¿å›¾"] = fig_line
    st.plotly_chart(fig_line, use_container_width=True)

    st.markdown("---")
    # ================= é›·è¾¾å›¾ï¼ˆå„ç§‘æ ¡æ¬¡æ’åå¯¹æ¯”ï¼‰ =================
    st.subheader("ğŸ•¸ï¸ é›·è¾¾å›¾ï¼šå„ç§‘æ ¡æ¬¡æ’åå¯¹æ¯”")
    # é€‰è€ƒè¯•æ ‡ç­¾ï¼ˆå¤šé€‰ï¼‰
    # å¤ç”¨æ€»åˆ†çš„æ—¶é—´åºåˆ—æ¥æä¾›è€ƒè¯•é¡ºåºï¼ˆè‹¥æ²¡æœ‰æ€»åˆ†ï¼Œåˆ™å›é€€ä¸ºæ•´ä½“çš„è€ƒè¯•æ ‡ç­¾é¡ºåºï¼‰
    total_rank_long = ts_long[ts_long["é¡¹ç›®"] == "æ€»åˆ†_æ ¡æ¬¡"].copy()
    if not total_rank_long.empty:
        available_exams = list(dict.fromkeys(total_rank_long.sort_values("è€ƒè¯•é¡ºåº")["è€ƒè¯•æ ‡ç­¾"]))
    else:
        available_exams = list(dict.fromkeys(ts_long.sort_values("è€ƒè¯•é¡ºåº")["è€ƒè¯•æ ‡ç­¾"]))
    selected_exams_for_radar = st.multiselect("é€‰æ‹©è¦æ¯”è¾ƒçš„è€ƒè¯• (2~3 æ¬¡æ›´ç›´è§‚)", available_exams, default=available_exams[-2:] if len(available_exams) >= 2 else available_exams)

    if selected_exams_for_radar:
        # å¤åˆç§‘ç›®ï¼ˆè¯­æ•°è‹±/7é€‰3ï¼‰ä¸çº³å…¥é›·è¾¾å›¾ï¼Œé¿å…ä¸å•ç§‘æ··åˆ
        subjects_for_radar = [s for s in subjects if s not in COMPOSITE_SUBJECTS]
        radar_subject_ranks = ts_long[(ts_long["å§“å"] == student_name) & (ts_long["è€ƒè¯•æ ‡ç­¾"].isin(selected_exams_for_radar))]
        # ä»…ä¿ç•™å­¦ç§‘ rank è¡Œ
        subj_rank_mask = radar_subject_ranks["é¡¹ç›®"].isin([f"{s}_æ ¡æ¬¡" for s in subjects_for_radar])
        radar_subject_ranks = radar_subject_ranks[subj_rank_mask].copy()
        radar_subject_ranks["å­¦ç§‘"] = radar_subject_ranks["é¡¹ç›®"].str.replace("_æ ¡æ¬¡", "", regex=False)
        transformed = transform_rank_for_radar(radar_subject_ranks)
        # æ„é€ é›·è¾¾
        fig_radar = go.Figure()
        categories = [s for s in subjects_for_radar if s in transformed["å­¦ç§‘"].unique()]
        if not categories:
            st.info("æ‰€é€‰è€ƒè¯•ç¼ºå°‘å­¦ç§‘æ’åæ•°æ®ã€‚")
        else:
            max_val = transformed["é›·è¾¾å€¼"].max() if "é›·è¾¾å€¼" in transformed.columns else None
            if pd.isna(max_val) or max_val is None:
                max_val = 1
            for exam in selected_exams_for_radar:
                sub = transformed[transformed["è€ƒè¯•æ ‡ç­¾"] == exam]
                sub = sub.set_index("å­¦ç§‘").reindex(categories)
                r_vals = sub["é›·è¾¾å€¼"].tolist() if "é›·è¾¾å€¼" in sub.columns else [None]*len(categories)
                fig_radar.add_trace(go.Scatterpolar(r=r_vals, theta=categories, fill='toself', name=exam))
            fig_radar.update_layout(title=f"{student_name} å„ç§‘æ’åé›·è¾¾å›¾ (æ•°å€¼å·²åè½¬ï¼Œé¢ç§¯è¶Šå¤§è¡¨ç¤ºæ’åè¶Šå‰)", polar=dict(radialaxis=dict(visible=True, range=[0, max_val])), showlegend=True)
            st.plotly_chart(fig_radar, use_container_width=True)
            export_figs[f"{student_name} å„ç§‘æ’åé›·è¾¾å›¾"] = fig_radar

   
    st.caption("æç¤ºï¼šé›·è¾¾å›¾æ•°å€¼å¯¹æ’ååšäº†åè½¬ï¼Œé¢ç§¯è¶Šå¤§è¡¨ç¤ºåæ¬¡è¶Šå‰ã€‚è‹¥æŸç§‘ç¼ºå¤±æ’ååˆ™è¯¥ç§‘ä¸ºç©ºã€‚")


    st.markdown("---")  

    # ================= æ€»åˆ†è·¨è€ƒè¯•æŸ±çŠ¶å¯¹æ¯” =================
    st.subheader("ğŸ“Š æ€»åˆ†è·¨è€ƒè¯•å¯¹æ¯”")
    if "æ€»åˆ†" in filtered_df.columns:
        total_df = filtered_df[filtered_df["å§“å"] == student_name][["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº", "æ€»åˆ†"]].copy()
        total_df["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(total_df["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)
        if total_df.empty:
            st.info("è¯¥å­¦ç”Ÿæ— æ€»åˆ†æ•°æ®å¯å¯¹æ¯”ã€‚")
        else:
            total_df["æ˜¾ç¤ºæ€»åˆ†"] = total_df["æ€»åˆ†"].apply(_fmt_one_decimal)
            fig_total = px.bar(
                total_df.sort_values("è€ƒè¯•é¡ºåº"),
                x="è€ƒè¯•æ ‡ç­¾", y="æ€»åˆ†", text="æ˜¾ç¤ºæ€»åˆ†", color="è€ƒè¯•æ ‡ç­¾",
                category_orders={"è€ƒè¯•æ ‡ç­¾": exam_label_order},
                title=f"{student_name} å†æ¬¡è€ƒè¯•æ€»åˆ†å¯¹æ¯”"
            )
            fig_total.update_traces(texttemplate="%{text}", textposition="outside")
            # è‡ªé€‚åº”Yè½´èµ·å§‹å€¼
            if auto_y_start and total_df["æ€»åˆ†"].notna().any():
                vmin = float(total_df["æ€»åˆ†"].min())
                vmax = float(total_df["æ€»åˆ†"].max())
                y0 = max(0.0, vmin - float(offset_y))
                y1 = vmax * 1.05 if vmax > 0 else 1.0
                fig_total.update_yaxes(range=[y0, y1])
            
            fig_total.update_layout(yaxis_title="æ€»åˆ†", xaxis_title="è€ƒè¯•", height=420, showlegend=False)
            st.plotly_chart(fig_total, use_container_width=True)
            export_figs[f"{student_name} å†æ¬¡è€ƒè¯•æ€»åˆ†å¯¹æ¯”"] = fig_total
    else:
        st.info("æœªæ‰¾åˆ°æ€»åˆ†åˆ—ã€‚")

    # ===== åœ¨æ­¤é»˜è®¤å¢åŠ ï¼šè¯­æ•°è‹± ä¸ 7é€‰3 çš„è·¨è€ƒè¯•å¯¹æ¯”ï¼ˆåŒä¸€å›¾ï¼šx=ç§‘ç›®ï¼Œé¢œè‰²=è€ƒè¯•æ ‡ç­¾ï¼Œy=æˆç»©ï¼‰ =====
    comp_candidates = ["è¯­æ•°è‹±", "7é€‰3"]
    present_comps = [c for c in comp_candidates if c in filtered_df.columns]
    comp_src = filtered_df[filtered_df["å§“å"] == student_name]
    if present_comps and not comp_src.empty:
        comp_long = (
            comp_src[["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"] + present_comps]
            .melt(id_vars=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"], value_vars=present_comps, var_name="ç§‘ç›®", value_name="åˆ†æ•°")
        )
        # ä¿æŒè€ƒè¯•é¡ºåºä¸ç§‘ç›®é¡ºåº
        comp_long["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(comp_long["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)
        subj_order_comp = [s for s in comp_candidates if s in comp_long["ç§‘ç›®"].unique()]
        comp_long["ç§‘ç›®"] = pd.Categorical(comp_long["ç§‘ç›®"], categories=subj_order_comp, ordered=True)

        if comp_long["åˆ†æ•°"].notna().any():
            comp_long["æ˜¾ç¤ºåˆ†æ•°"] = comp_long["åˆ†æ•°"].apply(_fmt_one_decimal)
            fig_comp_mix = px.bar(
                comp_long.sort_values(["ç§‘ç›®", "è€ƒè¯•é¡ºåº"]),
                x="ç§‘ç›®", y="åˆ†æ•°", color="è€ƒè¯•æ ‡ç­¾", text="æ˜¾ç¤ºåˆ†æ•°",
                barmode="group",
                category_orders={"ç§‘ç›®": subj_order_comp, "è€ƒè¯•æ ‡ç­¾": exam_label_order},
                title=f"{student_name} å†æ¬¡è€ƒè¯• è¯­æ•°è‹±/7é€‰3 å¯¹æ¯”"
            )
            fig_comp_mix.update_traces(texttemplate="%{text}", textposition="outside")
            if auto_y_start and comp_long["åˆ†æ•°"].notna().any():
                vmin = float(comp_long["åˆ†æ•°"].min())
                vmax = float(comp_long["åˆ†æ•°"].max())
                y0 = max(0.0, vmin - float(offset_y))
                y1 = vmax * 1.05 if vmax > 0 else 1.0
                fig_comp_mix.update_yaxes(range=[y0, y1])
            fig_comp_mix.update_layout(yaxis_title="åˆ†æ•°", xaxis_title="ç§‘ç›®", height=420)
            st.plotly_chart(fig_comp_mix, use_container_width=True)
            export_figs[f"{student_name} å†æ¬¡è€ƒè¯• è¯­æ•°è‹±_7é€‰3 å¯¹æ¯”"] = fig_comp_mix
        else:
            st.info("è¯¥å­¦ç”Ÿåœ¨å¤åˆç§‘ç›®ï¼ˆè¯­æ•°è‹±/7é€‰3ï¼‰æ²¡æœ‰æœ‰æ•ˆåˆ†æ•°å¯å¯¹æ¯”ã€‚")

    st.markdown("---")
    # ================= è·¨è€ƒè¯•æˆç»©å¯¹æ¯”ï¼ˆX=ç§‘ç›® é¢œè‰²=è€ƒè¯•ï¼Œæ’é™¤æ€»åˆ†ï¼‰ =================
    st.subheader("ğŸ“Š è·¨è€ƒè¯•æˆç»©å¯¹æ¯”ï¼ˆæŒ‰ç§‘ç›®åˆ†ç±»ï¼Œé¢œè‰²åŒºåˆ†è€ƒè¯•ï¼Œä¸å«æ€»åˆ†ï¼‰")
    if score_cols_subjects_only:
        score_all_long = (
            filtered_df[filtered_df["å§“å"] == student_name][["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"] + score_cols_subjects_only]
            .melt(id_vars=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"], var_name="ç§‘ç›®", value_name="åˆ†æ•°")
        )
        score_all_long["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(score_all_long["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)
        subject_order = [s for s in subjects if s in score_all_long["ç§‘ç›®"].unique()]
        score_all_long["ç§‘ç›®"] = pd.Categorical(score_all_long["ç§‘ç›®"], categories=subject_order, ordered=True)
        if score_all_long.empty:
            st.info("è¯¥å­¦ç”Ÿæ— å•ç§‘æˆç»©æ•°æ®å¯å¯¹æ¯”ã€‚")
        else:
            score_all_long["æ˜¾ç¤ºåˆ†æ•°"] = score_all_long["åˆ†æ•°"].apply(_fmt_one_decimal)
            fig_scores_all = px.bar(
                score_all_long.sort_values(["ç§‘ç›®", "è€ƒè¯•é¡ºåº"]),
                x="ç§‘ç›®", y="åˆ†æ•°", color="è€ƒè¯•æ ‡ç­¾", text="æ˜¾ç¤ºåˆ†æ•°",
                barmode="group",
                category_orders={"ç§‘ç›®": subject_order, "è€ƒè¯•æ ‡ç­¾": exam_label_order},
                title=f"{student_name} å†æ¬¡è€ƒè¯•å„ç§‘æˆç»©å¯¹æ¯”ï¼ˆé¢œè‰²=è€ƒè¯•æ ‡ç­¾ï¼‰"
            )
            fig_scores_all.update_traces(texttemplate="%{text}", textposition="outside")
            # è‡ªé€‚åº”Yè½´èµ·å§‹å€¼
            if auto_y_start and score_all_long["åˆ†æ•°"].notna().any():
                vmin = float(score_all_long["åˆ†æ•°"].min())
                vmax = float(score_all_long["åˆ†æ•°"].max())
                y0 = max(0.0, vmin - float(offset_y))
                y1 = vmax * 1.05 if vmax > 0 else 1.0
                fig_scores_all.update_yaxes(range=[y0, y1])
            fig_scores_all.update_layout(yaxis_title="åˆ†æ•°", xaxis_title="ç§‘ç›®", height=480)
            st.plotly_chart(fig_scores_all, use_container_width=True)
            export_figs[f"{student_name} å„ç§‘æˆç»©å¯¹æ¯”ï¼ˆé¢œè‰²=è€ƒè¯•æ ‡ç­¾ï¼‰"] = fig_scores_all
    else:
        st.info("æœªæ‰¾åˆ°å•ç§‘æˆç»©åˆ—ï¼Œæ— æ³•ç”Ÿæˆæˆç»©å¯¹æ¯”å›¾ã€‚")


    st.markdown("---")  
    # ================= è·¨è€ƒè¯•æ’åå¯¹æ¯”ï¼ˆX=ç§‘ç›® é¢œè‰²=è€ƒè¯•ï¼‰ =================
    st.subheader("ğŸ“Š è·¨è€ƒè¯•æ ¡æ¬¡æ’åå¯¹æ¯”ï¼ˆæŒ‰ç§‘ç›®åˆ†ç±»ï¼Œé¢œè‰²åŒºåˆ†è€ƒè¯•ï¼‰")
    rank_cols_exist = (["æ€»åˆ†_æ ¡æ¬¡"] if "æ€»åˆ†_æ ¡æ¬¡" in filtered_df.columns else []) + \
                      [f"{s}_æ ¡æ¬¡" for s in subjects if f"{s}_æ ¡æ¬¡" in filtered_df.columns]
    if rank_cols_exist:
        rank_long = (
            filtered_df[filtered_df["å§“å"] == student_name][["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"] + rank_cols_exist]
            .melt(id_vars=["è€ƒè¯•æ ‡ç­¾", "è€ƒè¯•é¡ºåº"], var_name="é¡¹ç›®", value_name="æ ¡æ¬¡æ’å")
        )
        rank_long["ç§‘ç›®"] = rank_long["é¡¹ç›®"].str.replace("_æ ¡æ¬¡", "", regex=False)
        rank_long.loc[rank_long["é¡¹ç›®"] == "æ€»åˆ†_æ ¡æ¬¡", "ç§‘ç›®"] = "æ€»åˆ†"
        rank_long["è€ƒè¯•æ ‡ç­¾"] = pd.Categorical(rank_long["è€ƒè¯•æ ‡ç­¾"], categories=exam_label_order, ordered=True)
        subject_order_rank = (["æ€»åˆ†"] if "æ€»åˆ†" in rank_long["ç§‘ç›®"].unique() else []) + [s for s in subjects if s in rank_long["ç§‘ç›®"].unique()]
        rank_long["ç§‘ç›®"] = pd.Categorical(rank_long["ç§‘ç›®"], categories=subject_order_rank, ordered=True)
        if rank_long.empty:
            st.info("è¯¥å­¦ç”Ÿæ— æ ¡æ¬¡æ’åæ•°æ®å¯å¯¹æ¯”ã€‚")
        else:
            rank_long["æ˜¾ç¤ºæ’å"] = rank_long["æ ¡æ¬¡æ’å"].apply(_fmt_one_decimal)
            fig_ranks_all = px.bar(
                rank_long.sort_values(["ç§‘ç›®", "è€ƒè¯•é¡ºåº"]),
                x="ç§‘ç›®", y="æ ¡æ¬¡æ’å", color="è€ƒè¯•æ ‡ç­¾", text="æ˜¾ç¤ºæ’å",
                barmode="group",
                category_orders={"ç§‘ç›®": subject_order_rank, "è€ƒè¯•æ ‡ç­¾": exam_label_order},
                title=f"{student_name} å†æ¬¡è€ƒè¯•å„ç§‘æ ¡æ¬¡æ’åå¯¹æ¯”ï¼ˆé¢œè‰²=è€ƒè¯•æ ‡ç­¾ï¼‰"
            )
            fig_ranks_all.update_traces(texttemplate="%{text}", textposition="outside")
            fig_ranks_all.update_yaxes(autorange="reversed")
            fig_ranks_all.update_layout(yaxis_title="åæ¬¡(è¶Šå°è¶Šå¥½)", xaxis_title="ç§‘ç›®", height=480)
            st.plotly_chart(fig_ranks_all, use_container_width=True)
            export_figs[f"{student_name} å„ç§‘æ ¡æ¬¡æ’åå¯¹æ¯”ï¼ˆé¢œè‰²=è€ƒè¯•æ ‡ç­¾ï¼‰"] = fig_ranks_all

    
